{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "import re\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import datetime as dt\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing NLTK feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnltk.download('stopwords')\\nnltk.download('punkt')\\nnltk.download('sentiwordnet')\\nnltk.download('wordnet')\\nnltk.download('omw-1.4')\\nnltk.download('averaged_perceptron_tagger')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Keywords for Socio Economic Causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "socio_economic_keywords = [\n",
    "    \"Poverty\",\n",
    "    \"Inequality\",\n",
    "    \"Unemployment\",\n",
    "    \"Economic disparity\",\n",
    "    \"Social justice\",\n",
    "    \"Wealth gap\",\n",
    "    \"Income inequality\",\n",
    "    \"Education access\",\n",
    "    \"Healthcare access\",\n",
    "    \"Housing crisis\",\n",
    "    \"Labor rights\",\n",
    "    \"Minimum wage\",\n",
    "    \"Economic empowerment\",\n",
    "    \"Gender pay gap\",\n",
    "    \"Racial discrimination\",\n",
    "    \"Access to resources\",\n",
    "    \"Food security\",\n",
    "    \"Social mobility\",\n",
    "    \"Economic development\",\n",
    "    \"Wealth distribution\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m all_results \u001b[39m=\u001b[39m []  \u001b[39m# Use a set to store unique article URLs\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m keyword \u001b[39min\u001b[39;00m socio_economic_keywords:\n\u001b[1;32m---> 21\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     22\u001b[0m     news\u001b[39m.\u001b[39msearch(keyword)\n\u001b[0;32m     23\u001b[0m     results \u001b[39m=\u001b[39m news\u001b[39m.\u001b[39mresults(sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "news = GoogleNews(lang='en', region='IN')\n",
    "news.set_lang('en')\n",
    "news.set_encode('utf-8')\n",
    "\n",
    "start_date = dt.date(2023, 1, 1)\n",
    "end_date = dt.date(2023, 5, 1)\n",
    "current_date = start_date\n",
    "search_query = '\"' + '\" \"'.join(socio_economic_keywords) + '\"'\n",
    "\n",
    "while current_date <= end_date:\n",
    "    period_end_date = current_date + dt.timedelta(days=30)\n",
    "    if period_end_date > end_date:\n",
    "        period_end_date = end_date\n",
    "    \n",
    "    while current_date <= period_end_date:\n",
    "        sdate = current_date.strftime('%Y-%m-%d')\n",
    "        edate = (current_date + dt.timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        all_results = [] \n",
    "        \n",
    "        for keyword in search_query:\n",
    "            time.sleep(10)\n",
    "            news.search(keyword)\n",
    "            results = news.results(sort=True)\n",
    "            all_results.extend(results)\n",
    "\n",
    "        if all_results:\n",
    "            time.sleep(11)\n",
    "            df = pd.DataFrame(all_results)\n",
    "            \n",
    "        current_date += dt.timedelta(days=30)\n",
    "     \n",
    "    if current_date <= end_date:\n",
    "        time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
